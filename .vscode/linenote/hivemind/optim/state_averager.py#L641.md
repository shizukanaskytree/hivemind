这个可以理解为 pull

reversely, it can be deemed as push.


```
load_state_from_peers (/home/wxf/hm_prj/hm_master/hivemind/hivemind/optim/state_averager.py:646)
load_state_from_peers (/home/wxf/hm_prj/hm_master/hivemind/hivemind/optim/optimizer.py:686)
on_train_begin (/home/wxf/hm_prj/hm_master/hivemind/examples/albert/run_trainer.py:99)
call_event (/home/wxf/anaconda3/envs/hm_master/lib/python3.8/site-packages/transformers/trainer_callback.py:378)
on_train_begin (/home/wxf/anaconda3/envs/hm_master/lib/python3.8/site-packages/transformers/trainer_callback.py:340)
train (/home/wxf/anaconda3/envs/hm_master/lib/python3.8/site-packages/transformers/trainer.py:1216)
main (/home/wxf/hm_prj/hm_master/hivemind/examples/albert/run_trainer.py:326)
<module> (/home/wxf/hm_prj/hm_master/hivemind/examples/albert/run_trainer.py:330)
```

依照顺序

```py
load_state_from_peers (/home/wxf/hm_prj/hm_master/hivemind/hivemind/optim/state_averager.py:646)

class TrainingStateAverager(DecentralizedAverager):

    def load_state_from_peers(self, **kwargs):
        """
        Attempt to download the latest optimizer state from peers and update trainer parameters/statistics.
        :returns: whether or the averager succeeded in loading parameters
        """
        opt_parameters = tuple(param for param_group in self.optimizer.param_groups for param in param_group["params"])
        main_parameters_and_extras = tuple(chain(opt_parameters, self.extra_tensors))
        num_parameters_and_extras = len(main_parameters_and_extras)

        loaded_state = super().load_state_from_peers(**kwargs)
        if loaded_state is None:
            return

        metadata, flat_tensors = loaded_state
        if (not isinstance(metadata.get("epoch"), int)) or metadata["epoch"] < self.local_epoch:
            logger.warning("Cowardly refusing to load state from peer: peer's epoch is behind our local epoch")
            return

        loaded_parameters_and_extras = flat_tensors[:num_parameters_and_extras]
        loaded_opt_tensors = flat_tensors[num_parameters_and_extras:]
        if num_parameters_and_extras != len(loaded_parameters_and_extras):
            logger.error("Failed to load state from peer, received parameters, extras or metadata")
            return

        with torch.no_grad(), self.lock_averaged_tensors:
            try:
                load_optimizer_state(self.optimizer, metadata["optimizer_metadata"], loaded_opt_tensors)
            except StopIteration:
                logger.warning("Failed to load state from peer, received inconsistent number of optimizer statistics")
                return

            for local_param, loaded_param in zip(main_parameters_and_extras, loaded_parameters_and_extras):
                local_param.copy_(loaded_param, non_blocking=True)

        if self.offload_optimizer:
            self._apply_optimizer_parameters_()
        if not self.reuse_tensors:
            self._load_local_tensors_into_averager_()

        self.local_epoch = metadata["epoch"]
        self._update_scheduler()
```


```py

load_state_from_peers (/home/wxf/hm_prj/hm_master/hivemind/hivemind/optim/optimizer.py:686)


class Optimizer(torch.optim.Optimizer):

    def load_state_from_peers(self, **kwargs):
        """
        Attempt to load the newest collaboration state from other peers within the same run_id.

        If successful, this will update parameters, optimizer state, local epoch and learning rate schedule in-place.
        """
        # note: we tag along for the next all-reduce because the run may have already started and cancelling it
        # will cause peers to restart matchmaking and may  stall the entire collaboration for a few seconds.
        if self.scheduled_grads is not None and not self.scheduled_grads.done():
            self._tag_along_with_zero_weight(self.scheduled_grads)
            self.scheduled_grads = None
        self.state_averager.step(wait_for_delayed_updates=True)

        with self.tracker.pause_updates():
            while True:
                try:
                    self.state_averager.load_state_from_peers(timeout=self.load_state_timeout, **kwargs)
                    break
                except KeyboardInterrupt:
                    raise
                except BaseException as e:
                    logger.exception(f"Failed to load state from peers: {e}, retrying ...")
                    continue

            if self.tracker.global_epoch - 1 <= self.local_epoch < self.tracker.global_epoch:
                logger.log(self.status_loglevel, f"Catching up with collaboration step {self.tracker.global_epoch}")
                self.state_averager.local_epoch = self.tracker.global_epoch

            self.tracker.report_local_progress(local_epoch=self.local_epoch, samples_accumulated=0)

            if not self.client_mode:
                self.state_averager.state_sharing_priority = self.local_epoch

            if self.use_gradient_averaging:
                self.grad_averager.reset_accumulated_grads_()
                if not self.client_mode:
                    self.grad_averager.state_sharing_priority = self.local_epoch

```



```py
on_train_begin (/home/wxf/hm_prj/hm_master/hivemind/examples/albert/run_trainer.py:99)

class CollaborativeCallback(transformers.TrainerCallback):

    def on_train_begin(
        self, args: TrainingArguments, state: transformers.TrainerState, control: transformers.TrainerControl, **kwargs
    ):
        logger.info("Loading state from peers")
        self.optimizer.load_state_from_peers()
```


```py
train (/home/wxf/anaconda3/envs/hm_master/lib/python3.8/site-packages/transformers/trainer.py:1216)

    # Training
    if training_args.do_train:
        latest_checkpoint_dir = max(
            Path(training_args.output_dir).glob("checkpoint*"), default=None, key=os.path.getctime
        )

        trainer.train(model_path=latest_checkpoint_dir)
```





# LOC

```py
opt_parameters = tuple(param for param_group in self.optimizer.param_groups for param in param_group["params"])
```


等价于

```py
for param_group in self.optimizer.param_groups:
    for param in param_group["params"]:
        param
```


# 结果


```
opt_parameters
(tensor([[-0.0237, -0...grad=True), tensor([[ 7.0347e-03...grad=True), tensor([[-3.5725e-03...grad=True), tensor([[-6.5642e-03...grad=True), tensor([0.6157, 0.68...grad=True), tensor([[ 0.0045, -0...grad=True), tensor([[ 0.0070,  0...grad=True), tensor([[ 0.0185,  0...grad=True), tensor([[-0.0278, -0...grad=True), tensor([[-0.0234,  0...grad=True), tensor([[-1.5675e-02...grad=True), tensor([[ 0.0072,  0...grad=True), tensor([[ 0.0214,  0...grad=True), tensor([[-0.0002, -0...grad=True), ...)
special variables:
function variables:
00: tensor([[-0.0237, -0.0232, -0.0209,  ..., -0.0228,  0.0222,  0.0221],
        [-0.0223, -0.0032, -0.0367,  ..., -0.0241,  0.0205,  0.0213],
        [-0.0192, -0.0428, -0.0299,  ..., -0.0245,  0.0108,  0.0050],
        ...,
        [-0.0397, -0.0253, -0.0129,  ...,  0.0044,  0.0087,  0.0613],
        [-0.0101, -0.0162,  0.0070,  ..., -0.0075, -0.0096,  0.0221],
        [-0.0256, -0.0015, -0.0137,  ...,  0.0157,  0.0261,  0.0388]],
       requires_grad=True)
01: tensor([[ 7.0347e-03, -2.7859e-03,  3.0935e-04,  ..., -2.5454e-03,
         -1.1007e-02, -4.4500e-05],
        [ 2.9826e-03,  2.2780e-04, -9.4263e-04,  ...,  4.2338e-03,
         -7.5183e-03, -1.1246e-03],
        [-1.9743e-03, -4.9266e-03, -3.8946e-03,  ..., -1.3835e-03,
         -4.2873e-05, -5.7045e-03],
        ...,
        [ 5.1968e-03, -1.8678e-03, -6.7434e-03,  ..., -1.7068e-03,
         -7.4910e-03,  1.2719e-03],
        [-6.8274e-04,  7.0441e-03, -3.3382e-04,  ..., -1.0300e-04,
         -3.1097e-03, -1.1004e-03],
        [ 7.6030e-03, -5.7270e-03,  2.2594e-03,  ..., -7.9484e-03,
         -5.7801e-03,  5.1960e-03]], requires_grad=True)
02: tensor([[-3.5725e-03, -2.2793e-03, -7.2209e-03,  6.2866e-03, -2.3313e-03,
         -8.4222e-03,  8.3713e-03, -6.2827e-04, -8.6839e-03, -1.4741e-02,
          8.0875e-04, -8.2737e-03, -2.4563e-03,  7.2471e-03, -2.5823e-03,
          4.2610e-03,  7.0515e-03, -1.1237e-03,  7.3271e-03, -3.4885e-03,
          2.7247e-03,  1.2257e-03, -7.2277e-03, -6.1745e-03,  1.9800e-03,
          3.1096e-03, -9.0302e-04,  5.8746e-03,  5.3402e-03, -5.3251e-03,
         -6.0768e-03, -2.5693e-03, -2.4769e-05,  5.7233e-03,  4.2430e-03,
         -1.9735e-03, -1.5062e-03,  1.8840e-03, -1.8724e-03,  1.6172e-04,
         -1.3053e-03, -8.0913e-03, -4.6094e-03,  2.7721e-03, -2.6132e-04,
          8.9300e-04,  2.4977e-03, -8.0139e-03,  3.2387e-03, -4.0056e-03,
          1.3422e-02,  8.5265e-03, -3.5319e-04,  3.2174e-03,  4.2439e-03,
         -1.2949e-02,  2.3827e-03, -4.2892e-03, -8.6890e-04,  5.9609e-03,
         -3.9257e-03, -5.0439e-03, -1.6120e-03, -2.2626e-03, -6.8422e-03,
          4.1526e-03,  4.6561e-03, -2.9468e-03, -2.8644e-03, -7.4167e-04,
         -4.5669e-04, -5.5742e-04, -8.7494e-03, -3.1949e-03,  5.1756e-03,
          9.5605e-03, -1.3477e-03,  5.7425e-04,  1.8556e-03,  7.1433e-03,
          5.7094e-03,  9.4800e-03,  9.3868e-03, -7.2104e-03, -4.9268e-03,
         -2.5346e-03, -1.0698e-02,  2.4551e-04,  7.8968e-03,  4.6767e-03,
         -3.0839e-03,  5.9919e-04, -8.4925e-03, -2.9584e-03, -6.8883e-03,
          1.9193e-03,  3.0812e-03,  5.1634e-03, -9.4409e-05, -9.4708e-04,
          9.9196e-04, -2.2077e-04, -1.9830e-03, -4.4410e-03,  3.1848e-03,
          7.8353e-03,  9.4941e-03, -4.9641e-03, -1.9408e-04, -1.1706e-03,
         -7.9724e-05,  1.5153e-03,  7.2713e-04, -2.5204e-03, -3.6029e-04,
         -8.5318e-03,  4.2428e-04, -5.3404e-03, -3.5137e-03,  3.7801e-03,
          5.6491e-04, -2.3353e-04, -5.0585e-03, -5.9800e-03, -2.9951e-03,
          3.4538e-03,  4.9973e-03, -2.6792e-03],
        [ 3.6718e-03, -1.4921e-03,  3.3446e-03,  7.9558e-03,  3.2801e-03,
          3.2575e-03,  8.0329e-03, -1.9352e-04,  4.0512e-03, -4.5807e-03,
          1.3368e-03,  8.2090e-03,  1.4303e-03,  1.1206e-03,  4.8481e-03,
          4.9658e-03,  5.6705e-04,  5.9788e-04, -2.3457e-03, -4.7816e-04,
         -1.5131e-03,  3.5578e-03,  5.3215e-03, -1.2594e-04, -1.1724e-03,
          1.0761e-04,  7.2413e-04,  8.0466e-03,  7.0385e-03, -3.3818e-03,
         -4.2314e-04, -4.7725e-03, -6.7101e-03, -1.1901e-02, -2.3774e-03,
         -3.8454e-03, -7.6560e-03, -1.9339e-03,  5.4052e-03, -4.5297e-04,
          3.8266e-03, -3.5556e-03, -1.6409e-03, -4.0096e-03, -2.6354e-03,
         -2.1105e-03,  1.7736e-03, -5.4474e-03,  4.2291e-03, -1.0279e-02,
          6.9080e-04,  5.7913e-03, -4.9716e-03, -6.1041e-04, -8.2417e-03,
          3.4873e-03,  3.7359e-03,  7.2499e-03,  9.3921e-03,  2.6159e-03,
          7.2958e-03, -4.1414e-03,  4.8470e-03, -5.4205e-03, -8.8178e-03,
          5.0139e-04,  7.8179e-03, -2.9508e-03, -1.4714e-03,  3.5239e-03,
          3.6360e-03, -1.5010e-03, -2.7991e-04,  4.1581e-03,  1.4763e-04,
         -5.3040e-04,  2.3333e-04, -4.2886e-03, -2.8568e-03, -4.2897e-03,
         -2.1707e-03,  7.2398e-03, -6.2133e-03,  8.8447e-03,  3.8652e-03,
          5.0846e-04, -8.7321e-03,  9.7763e-04, -8.5871e-03, -8.8308e-03,
         -3.3482e-03,  1.3052e-03, -3.9627e-03, -3.1060e-03, -1.3452e-02,
         -1.6092e-03,  1.8509e-03, -9.2973e-03, -4.3382e-03,  2.1008e-03,
          2.4167e-03, -3.0146e-03, -7.2665e-03,  6.7929e-04, -2.3921e-05,
         -7.6627e-03,  1.0062e-03,  2.9445e-03,  1.1269e-02, -5.0481e-03,
          6.8173e-03,  2.4680e-03, -6.5391e-04,  3.3577e-03,  5.5211e-03,
         -6.3438e-03,  1.1214e-03, -1.6332e-03, -9.8094e-03,  3.4465e-03,
          6.2361e-03, -6.6743e-03,  5.3690e-03,  3.4054e-03, -1.4130e-03,
          2.8880e-03, -1.9863e-03,  4.2890e-03]], requires_grad=True)
03: tensor([[-6.5642e-03, -8.3174e-06, -5.9820e-03,  ...,  5.5924e-03,
          7.8638e-04, -6.4967e-03],
        [ 3.7747e-03, -2.6141e-03, -1.5147e-03,  ...,  7.2409e-03,
         -3.8685e-03,  5.2470e-03],
        [ 3.3529e-03,  8.0881e-03,  5.4898e-03,  ...,  1.9210e-03,
          7.5434e-03, -3.8880e-03],
        ...,
        [ 1.0354e-02,  3.3689e-03, -5.7180e-03,  ...,  1.5856e-03,
          3.5077e-03, -2.0124e-04],
        [ 1.1782e-03,  3.8786e-03, -1.0843e-03,  ...,  1.1204e-03,
          4.1267e-03,  5.2406e-03],
        [ 1.6817e-03, -2.9645e-03, -5.8655e-03,  ..., -7.3724e-03,
         -6.4015e-03,  3.0634e-03]], requires_grad=True)
04: tensor([0.6157, 0.6814, 0.7622,  ..., 0.7807, 0.8489, 0.7935],
       requires_grad=True)
05: tensor([[ 0.0045, -0.0021,  0.0001,  ..., -0.0005, -0.0016,  0.0089],
        [-0.0033,  0.0041, -0.0045,  ...,  0.0056, -0.0008, -0.0081],
        [-0.0076, -0.0034,  0.0056,  ...,  0.0017, -0.0072, -0.0032],
        ...,
        [-0.0050, -0.0048,  0.0068,  ...,  0.0036,  0.0003, -0.0128],
        [-0.0062,  0.0063,  0.0061,  ...,  0.0066,  0.0054, -0.0046],
        [-0.0035,  0.0004,  0.0065,  ...,  0.0041,  0.0048,  0.0012]],
       requires_grad=True)
06: tensor([[ 0.0070,  0.0104,  0.0007,  ...,  0.0004, -0.0007,  0.0003],
        [-0.0057, -0.0003,  0.0014,  ...,  0.0001,  0.0096,  0.0028],
        [ 0.0050, -0.0063, -0.0024,  ...,  0.0013, -0.0053, -0.0074],
        ...,
        [-0.0023, -0.0104, -0.0055,  ...,  0.0057, -0.0022,  0.0010],
        [-0.0007,  0.0025,  0.0057,  ...,  0.0029, -0.0016,  0.0026],
        [-0.0006, -0.0038,  0.0014,  ...,  0.0003,  0.0032,  0.0091]],
       requires_grad=True)
07: tensor([[ 0.0185,  0.0294,  0.0135,  ..., -0.0085, -0.0007, -0.0130],
        [-0.0134, -0.0156,  0.0120,  ...,  0.0010,  0.0224,  0.0051],
        [-0.0198,  0.0012,  0.0089,  ..., -0.0109, -0.0121, -0.0094],
        ...,
        [ 0.0242, -0.0293,  0.0070,  ..., -0.0368,  0.0126,  0.0021],
        [ 0.0254,  0.0137,  0.0149,  ...,  0.0178,  0.0098, -0.0039],
        [-0.0247,  0.0156, -0.0046,  ..., -0.0005,  0.0020,  0.0063]],
       requires_grad=True)
08: tensor([[-0.0278, -0.0243,  0.0060,  ..., -0.0066,  0.0037,  0.0273],
        [ 0.0142,  0.0038, -0.0163,  ..., -0.0187,  0.0399,  0.0267],
        [-0.0008,  0.0114,  0.0114,  ...,  0.0024, -0.0064,  0.0077],
        ...,
        [ 0.0077,  0.0190,  0.0029,  ..., -0.0092,  0.0177, -0.0220],
        [-0.0053,  0.0020, -0.0102,  ...,  0.0120, -0.0273,  0.0275],
        [ 0.0066,  0.0200,  0.0389,  ..., -0.0086, -0.0185,  0.0009]],
       requires_grad=True)
09: tensor([[-0.0234,  0.0126, -0.0089,  ..., -0.0126, -0.0034,  0.0312],
        [-0.0181, -0.0008, -0.0066,  ...,  0.0013,  0.0005,  0.0122],
        [-0.0065,  0.0317, -0.0113,  ...,  0.0234, -0.0161, -0.0307],
        ...,
        [ 0.0200, -0.0182, -0.0198,  ..., -0.0047, -0.0328,  0.0099],
        [ 0.0016, -0.0110, -0.0190,  ..., -0.0064, -0.0186,  0.0086],
        [ 0.0272, -0.0073,  0.0068,  ...,  0.0090,  0.0180,  0.0115]],
       requires_grad=True)
10: tensor([[-1.5675e-02,  1.5414e-02,  1.5744e-02,  ...,  1.7177e-02,
          4.1461e-03, -3.6316e-02],
        [-1.5039e-02,  2.1214e-02,  7.8740e-03,  ...,  1.2372e-02,
         -3.8404e-02, -2.6513e-02],
        [ 1.8449e-02, -6.1271e-03, -3.3749e-03,  ..., -1.2810e-02,
         -1.4969e-02,  4.4078e-03],
        ...,
        [ 2.1173e-03, -1.9986e-02, -2.0176e-04,  ...,  1.5414e-02,
         -3.0756e-02, -1.2584e-02],
        [-1.5822e-02,  8.6330e-04, -1.2375e-02,  ..., -1.1702e-02,
          1.5849e-02,  1.4847e-02],
        [-1.4528e-02, -4.3896e-03,  4.0426e-04,  ..., -1.3441e-02,
         -4.1858e-03,  9.7474e-05]], requires_grad=True)
11: tensor([[ 0.0072,  0.0404,  0.0319,  ..., -0.0020,  0.0072,  0.0158],
        [ 0.0140,  0.0039,  0.0323,  ..., -0.0199, -0.0112,  0.0027],
        [ 0.0174, -0.0039, -0.0113,  ...,  0.0054, -0.0154, -0.0127],
        ...,
        [-0.0106,  0.0638,  0.0360,  ..., -0.0071,  0.0071,  0.0048],
        [ 0.0219, -0.0180,  0.0144,  ..., -0.0224,  0.0253,  0.0014],
        [-0.0193, -0.0147,  0.0114,  ...,  0.0140,  0.0403, -0.0066]],
       requires_grad=True)
12: tensor([[ 0.0214,  0.0141,  0.0323,  ...,  0.0137,  0.0062, -0.0325],
        [ 0.0204, -0.0190,  0.0137,  ...,  0.0011,  0.0206,  0.0167],
        [-0.0236, -0.0047, -0.0134,  ..., -0.0051,  0.0166, -0.0259],
        ...,
        [-0.0171,  0.0067, -0.0380,  ...,  0.0186, -0.0064, -0.0221],
        [ 0.0102, -0.0495,  0.0425,  ..., -0.0293,  0.0122,  0.0091],
        [-0.0114,  0.0334, -0.0245,  ...,  0.0094, -0.0093, -0.0029]],
       requires_grad=True)
13: tensor([[-0.0002, -0.0078,  0.0145,  ..., -0.0030, -0.0163, -0.0355],
        [ 0.0206,  0.0013,  0.0010,  ..., -0.0068,  0.0105, -0.0128]],
       requires_grad=True)
14: tensor([ 0.9918,  1.1280,  0.2732,  0.9720,  0.8836,  0.6186,  1.1509,  0.9897,
         0.8746,  0.8834,  0.9974,  1.1540,  0.8584,  0.5258,  1.0342,  0.9905,
         0.7663,  0.9898,  2.2383,  1.0565,  0.9110,  0.9122,  1.0115,  0.9356,
         1.2125,  1.1544,  0.9486,  0.9597,  1.1617,  0.8721,  0.8350,  1.0111,
         1.0469,  0.8053,  0.8906,  1.0329,  1.0687,  0.9499,  0.9565,  1.0789,
         0.7841,  1.3339,  0.6217,  1.3313,  1.0025,  0.9856,  0.8519,  0.9465,
         0.8551,  0.9180,  0.9571,  1.2290,  1.0432,  1.3523,  0.8272, -0.0345,
         1.0243,  0.9126,  1.0664,  0.9133,  0.9785,  1.2436,  0.9018,  0.9099,
         0.9982,  0.4359,  0.9064,  1.6489,  0.8542,  1.0332,  1.0667,  0.9642,
         1.3253,  1.0003,  0.6911,  1.1894,  0.8159,  1.0157,  1.1264,  0.7446,
         0.8706,  1.1727,  1.1209,  1.0389,  1.0215,  0.9269,  1.1922,  0.9811,
         1.7445,  0.9682,  0.8102,  1.0694,  1.0510,  0.8970,  1.1321,  0.6870,
         0.7266,  1.0345,  1.1173,  1.0686,  1.0634,  1.0660,  0.8478,  0.7925,
         1.1528,  0.8113,  1.3844,  1.0463,  0.9975,  1.0970,  1.0114,  0.9432,
         1.0541,  1.0604,  0.9947,  1.2434,  0.9774,  1.3024,  1.1237,  1.2087,
         1.0538,  1.0870,  0.7997,  0.9499,  0.8750,  1.0939,  0.8686,  0.9634],
       requires_grad=True)
15: tensor([ 3.2849e-07, -2.1508e-07,  2.6739e-07,  2.7052e-07, -2.1132e-07,
        -3.7940e-08, -1.8902e-07, -1.7154e-07, -2.1985e-07,  2.8476e-07,
         2.8983e-07,  1.7657e-07,  2.7238e-07,  2.1087e-07, -2.4487e-07,
        -2.4260e-07, -3.3980e-07,  1.7557e-07,  3.2087e-07,  1.1951e-07,
        -3.5784e-07, -2.4778e-07,  1.7504e-07, -2.8907e-07,  2.6546e-07,
         3.0379e-07,  2.1706e-08,  2.2600e-07, -1.5332e-07, -2.0731e-07,
         5.1000e-08,  2.4039e-07, -3.0174e-07, -4.0469e-07, -3.2034e-07,
         1.6320e-07, -2.0433e-07, -2.5655e-07,  3.6065e-07,  2.1267e-07,
         3.7860e-07,  1.9277e-07, -1.5230e-07,  3.3876e-07, -2.3079e-07,
         2.8747e-07,  6.6877e-08,  2.5270e-07, -2.9187e-07,  2.8396e-07,
         2.3093e-07, -2.2018e-07, -3.9519e-07, -2.5656e-07, -2.4487e-07,
         3.6576e-07,  5.5515e-08, -9.3529e-08, -1.6689e-07,  1.5693e-07,
        -2.7535e-07,  1.5574e-07, -2.2398e-07,  9.8659e-08, -2.7771e-07,
        -4.1201e-07, -2.8906e-07, -2.6297e-08,  3.7429e-07,  2.9946e-07,
        -2.2353e-07, -2.6957e-07,  1.7855e-07, -3.0371e-07, -3.4121e-07,
         3.2613e-07, -1.9477e-07, -2.0439e-07,  2.6543e-07, -3.3689e-07,
         1.5489e-07,  2.9296e-07, -2.8300e-07, -3.0286e-07, -2.6705e-07,
         3.4458e-07, -2.8917e-07, -2.6865e-07,  1.9190e-07, -3.0672e-07,
        -2.1977e-07, -2.1573e-07, -2.5248e-07,  3.2621e-07,  2.4491e-07,
         1.8308e-07,  1.5102e-07, -2.7089e-07, -3.3525e-07,  3.2872e-07,
        -1.6108e-07, -2.5743e-07, -1.0453e-07,  2.6048e-07, -2.6767e-07,
         1.5033e-07,  3.3191e-07,  2.9199e-07, -3.2155e-07,  1.9466e-07,
         1.5617e-07, -2.0253e-07,  3.2376e-07, -2.5617e-07,  3.1769e-07,
         1.5575e-07, -2.5706e-07,  1.4623e-07, -2.9251e-07,  3.6164e-07,
        -1.4628e-07,  1.2447e-07,  3.2187e-07, -3.0066e-07,  3.3332e-07,
         2.5632e-07,  9.7857e-08,  3.3236e-07], requires_grad=True)
16: tensor([-3.4418e-07, -8.7867e-08, -2.5064e-07,  ..., -2.8023e-07,
         2.8072e-07,  2.9955e-07], requires_grad=True)
17: tensor([-2.5354e-07,  2.9089e-07, -1.1173e-07,  ..., -2.1426e-07,
         3.5416e-07,  8.7728e-08], requires_grad=True)
18: tensor([-5.4308e-08,  6.7176e-11,  5.5536e-08,  ..., -6.8719e-08,
         5.6464e-08,  6.0408e-08], requires_grad=True)
19: tensor([ 1.9069e-10, -1.5126e-10, -5.2940e-11,  ...,  2.8961e-10,
         1.3749e-10,  7.8119e-11], requires_grad=True)
20: tensor([-1.9432e-07,  3.1892e-08,  1.8027e-07,  ..., -2.5116e-07,
         1.0059e-07, -2.3067e-07], requires_grad=True)
21: tensor([-3.1748e-07,  2.6483e-07, -1.8130e-07,  ..., -2.8349e-07,
         3.5711e-07,  2.2018e-07], requires_grad=True)
22: tensor([0.7842, 0.8732, 0.9497,  ..., 0.9491, 1.1087, 0.8030],
       requires_grad=True)
23: tensor([-2.7010e-07,  2.6982e-07,  2.3704e-07,  ..., -2.8652e-07,
         3.9665e-07, -2.5825e-07], requires_grad=True)
24: tensor([ 3.6757e-07, -2.5363e-07, -2.4741e-08,  ..., -1.9151e-07,
         1.7948e-07,  1.6054e-07], requires_grad=True)
25: tensor([-2.4606e-07,  2.9774e-07, -1.1731e-07,  ..., -2.2324e-07,
         3.4994e-07,  8.9834e-08], requires_grad=True)
26: tensor([ 1.4688e-07,  1.3064e-07, -8.9523e-08,  ..., -2.4765e-08,
         3.4481e-08,  1.9748e-07], requires_grad=True)
27: tensor([-1.4529e-08, -2.7716e-08, -2.2700e-08,  ..., -1.0944e-08,
        -1.4395e-08, -1.1379e-08], requires_grad=True)
28: tensor([ 1.7554,  1.8628,  1.6770, -0.0971,  1.8131,  1.8510,  2.0075,  1.8995,
         1.9600,  1.7781,  1.9320,  1.7948,  1.8791,  1.6514,  1.6990,  1.6813,
         2.1257,  1.7230,  1.5494,  1.6342,  1.6143,  0.1260,  1.9701,  1.6888,
         1.8677,  1.8152,  1.8886,  1.9168,  1.7867,  1.6930,  1.6918,  1.9315,
         1.4777,  1.6103,  1.8533,  1.7513,  1.8820,  1.0906,  1.4173,  1.8953,
         1.6309,  1.6798,  1.8306,  1.8790,  1.7788,  1.7984,  1.9945,  1.9304,
         1.6528,  1.7532, -0.7030,  1.7451,  1.9017,  1.7931,  1.8703,  1.6032,
         1.8947,  1.7985,  1.8843,  1.8392,  1.6814,  1.8940,  1.8608,  1.8346,
         1.8820,  1.3268,  1.9564,  1.9468,  0.0464,  1.9950,  1.9694, -0.0277,
         0.2126,  1.7433,  1.7512,  1.7034,  1.8251,  1.9671,  1.7009,  2.1112,
         0.3745,  1.8982,  1.9858,  1.8001,  1.8192,  1.8168,  1.8284,  1.6528,
         1.8911,  1.9462,  1.9447,  1.8591,  1.8566,  1.8232,  1.9420,  1.7599,
         1.9458,  1.8074,  1.9782,  1.9403,  1.8218,  1.5285,  1.8315,  1.7235,
         1.7775,  1.5681,  1.9031,  1.9425,  1.9353,  1.7361,  1.7609,  1.8109,
         2.0037,  1.8787,  1.8952,  1.9031,  1.7966,  1.8516,  1.9015,  1.6961,
         1.7087,  1.7300,  1.9202,  1.8732,  1.8772,  1.7202,  1.7750,  1.6800],
       requires_grad=True)
29: tensor([ 4.1654e-07,  3.1024e-07,  1.2056e-07, -1.0209e-07, -4.0689e-07,
         4.3500e-07, -3.1650e-07,  3.7307e-07,  2.6153e-07,  3.6433e-07,
        -3.6159e-07,  4.2643e-07, -4.1760e-07,  4.1102e-07,  3.4532e-07,
         3.5049e-08, -3.6928e-07,  4.2545e-07,  4.5825e-07,  4.1009e-07,
         3.0452e-07,  1.7104e-07, -3.8065e-07,  4.1738e-07,  3.1679e-07,
         4.3342e-07,  3.7659e-07, -4.3084e-07, -4.5714e-07,  4.1348e-07,
         4.1330e-07, -4.2568e-07, -3.0451e-07,  1.0658e-07, -4.0983e-07,
         4.2059e-07, -4.2051e-07,  2.4219e-07,  2.9268e-07, -4.2046e-07,
        -1.4505e-07,  4.1358e-07, -4.0678e-07,  4.3284e-07,  4.1886e-07,
        -3.9944e-07, -4.4794e-07, -3.6866e-07,  1.3538e-07, -3.9379e-07,
         2.8303e-07,  1.8874e-08, -4.2105e-07,  4.2720e-07, -4.1405e-07,
         1.0828e-07,  3.1116e-07,  3.6927e-07,  4.3054e-07, -2.3415e-07,
         4.1105e-07, -4.2511e-07, -3.5031e-07, -4.6923e-07, -4.1617e-07,
         7.6775e-08, -2.3226e-08, -4.3117e-07, -2.6468e-08, -3.8363e-07,
         3.2119e-07,  1.8392e-07,  6.7707e-09,  1.2266e-07,  3.5720e-07,
         4.2386e-07, -4.0418e-07, -4.4004e-07,  4.1331e-07, -3.9518e-07,
         2.3620e-07,  3.7798e-07, -3.8063e-07, -4.0369e-07,  4.2461e-07,
        -2.1690e-07, -4.4059e-09,  4.0952e-07,  3.7525e-07,  4.4734e-07,
        -4.2891e-07, -3.5267e-07, -4.1570e-07,  3.7176e-07, -3.6864e-07,
        -2.0108e-07, -4.3176e-07,  2.5428e-07, -2.4532e-07, -3.6791e-07,
        -1.1666e-07,  4.0186e-07, -4.1050e-07,  7.9903e-08,  4.2499e-07,
         4.5826e-07,  3.7658e-07, -4.3397e-07, -3.6976e-07, -2.0804e-07,
         4.2785e-07, -1.0381e-07, -3.8256e-07, -4.7850e-07, -3.5807e-07,
        -3.5683e-07,  4.2158e-07, -4.0915e-07, -3.6011e-07,  3.5218e-07,
         4.1705e-07,  4.2501e-07,  3.8109e-07, -4.2754e-07, -4.1668e-07,
         4.1470e-07, -3.9305e-07, -2.6107e-07], requires_grad=True)
30: tensor([ 3.4044e-07,  2.7745e-07,  2.7401e-07, -6.9624e-08, -1.9851e-07,
         2.7657e-07, -2.0047e-07,  2.7961e-07,  2.8133e-07,  2.7687e-07,
        -2.5959e-07,  2.6923e-07,  2.3194e-08, -1.4745e-07,  2.0396e-07,
         1.5309e-07, -1.8991e-07,  2.8011e-07,  3.3763e-07,  2.6961e-07,
         2.1831e-07,  1.3211e-07, -2.0966e-08,  3.3192e-07,  1.6509e-07,
         2.8107e-07,  3.2407e-07, -2.5256e-07, -3.0997e-07,  3.3613e-07,
         3.4565e-07,  1.6268e-07, -1.8822e-07,  2.1869e-07,  2.0113e-07,
         3.3516e-07, -2.7803e-07,  9.4384e-08,  2.6914e-07, -3.3211e-07,
        -7.8044e-08,  2.6906e-07, -2.1523e-08, -1.6876e-08,  3.3417e-07,
        -2.5828e-07, -3.6921e-07, -1.2915e-07,  2.8754e-07, -3.3716e-07,
         1.9650e-10,  2.0970e-07, -2.7250e-07,  1.0475e-07,  9.6045e-08,
        -2.2197e-07,  2.1480e-07,  2.2059e-07, -3.1491e-08, -1.4057e-07,
         3.2759e-07,  1.4833e-07, -2.0532e-07, -3.1711e-07, -2.7359e-07,
         1.5330e-07, -1.0539e-07, -2.7397e-07, -1.0871e-07, -2.5141e-07,
         1.5076e-07,  1.3904e-08,  7.2622e-08,  2.7215e-07,  3.4190e-08,
         2.8084e-07, -3.2182e-07, -2.6689e-07,  2.1711e-07, -2.5536e-07,
         2.4681e-08,  2.2147e-07, -2.5589e-07,  9.0273e-08,  3.3629e-07,
         1.1065e-07, -4.1897e-08,  2.6977e-07,  1.0326e-07,  1.6988e-07,
        -2.6457e-07, -2.5399e-07, -3.2852e-07,  2.7532e-07, -1.7755e-07,
         4.7659e-08, -2.6775e-07,  1.5731e-07, -1.3118e-07, -1.7401e-07,
        -2.0983e-08,  2.5773e-07, -2.6387e-07,  2.8454e-08, -8.0673e-08,
         2.8200e-07, -1.4636e-08, -2.5712e-07, -1.3498e-07, -1.2920e-07,
         2.8107e-07, -3.0151e-08, -2.5518e-07, -3.2849e-07, -2.5973e-07,
        -2.1153e-07, -2.7703e-08, -2.7938e-07, -2.6062e-07,  2.7079e-07,
         2.7555e-07,  9.7320e-08,  1.6854e-07,  1.4650e-07, -2.6401e-07,
         3.3793e-07, -3.2588e-07, -1.7708e-07], requires_grad=True)
31: tensor([-2.9787e-07,  2.9735e-07], requires_grad=True)
len(): 32
```



```
self.optimizer

Lamb (
Parameter Group 0
    betas: (0.9, 0.999)
    eps: 1e-06
    initial_lr: 0.00176
    lr: 0.0012274240000000002
    weight_decay: 0.01

Parameter Group 1
    betas: (0.9, 0.999)
    eps: 1e-06
    initial_lr: 0.00176
    lr: 0.0012274240000000002
    weight_decay: 0.0
)
```



```
self.optimizer.param_groups

[{'betas': (...), 'eps': 1e-06, 'initial_lr': 0.00176, 'lr': 0.0012274240000000002, 'weight_decay': 0.01, 'params': [...]}, {'betas': (...), 'eps': 1e-06, 'initial_lr': 0.00176, 'lr': 0.0012274240000000002, 'weight_decay': 0.0, 'params': [...]}]
special variables:
function variables:
0: {'betas': (0.9, 0.999), 'eps': 1e-06, 'initial_lr': 0.00176, 'lr': 0.0012274240000000002, 'weight_decay': 0.01, 'params': [tensor([[-0.0237, -0...grad=True), tensor([[ 7.0347e-03...grad=True), tensor([[-3.5725e-03...grad=True), tensor([[-6.5642e-03...grad=True), tensor([0.6157, 0.68...grad=True), tensor([[ 0.0045, -0...grad=True), tensor([[ 0.0070,  0...grad=True), tensor([[ 0.0185,  0...grad=True), tensor([[-0.0278, -0...grad=True), ...]}
1: {'betas': (0.9, 0.999), 'eps': 1e-06, 'initial_lr': 0.00176, 'lr': 0.0012274240000000002, 'weight_decay': 0.0, 'params': [tensor([ 0.9918,  1....grad=True), tensor([ 3.2849e-07,...grad=True), tensor([-3.4418e-07,...grad=True), tensor([-2.5354e-07,...grad=True), tensor([-5.4308e-08,...grad=True), tensor([ 1.9069e-10,...grad=True), tensor([-1.9432e-07,...grad=True), tensor([-3.1748e-07,...grad=True), tensor([0.7842, 0.87...grad=True), ...]}
len(): 2
```



```
param_group["params"]
[tensor([[-0.0237, -0...grad=True), tensor([[ 7.0347e-03...grad=True), tensor([[-3.5725e-03...grad=True), tensor([[-6.5642e-03...grad=True), tensor([0.6157, 0.68...grad=True), tensor([[ 0.0045, -0...grad=True), tensor([[ 0.0070,  0...grad=True), tensor([[ 0.0185,  0...grad=True), tensor([[-0.0278, -0...grad=True), tensor([[-0.0234,  0...grad=True), tensor([[-1.5675e-02...grad=True), tensor([[ 0.0072,  0...grad=True), tensor([[ 0.0214,  0...grad=True), tensor([[-0.0002, -0...grad=True)]
special variables:
function variables:
00: tensor([[-0.0237, -0.0232, -0.0209,  ..., -0.0228,  0.0222,  0.0221],
        [-0.0223, -0.0032, -0.0367,  ..., -0.0241,  0.0205,  0.0213],
        [-0.0192, -0.0428, -0.0299,  ..., -0.0245,  0.0108,  0.0050],
        ...,
        [-0.0397, -0.0253, -0.0129,  ...,  0.0044,  0.0087,  0.0613],
        [-0.0101, -0.0162,  0.0070,  ..., -0.0075, -0.0096,  0.0221],
        [-0.0256, -0.0015, -0.0137,  ...,  0.0157,  0.0261,  0.0388]],
       requires_grad=True)
01: tensor([[ 7.0347e-03, -2.7859e-03,  3.0935e-04,  ..., -2.5454e-03,
         -1.1007e-02, -4.4500e-05],
        [ 2.9826e-03,  2.2780e-04, -9.4263e-04,  ...,  4.2338e-03,
         -7.5183e-03, -1.1246e-03],
        [-1.9743e-03, -4.9266e-03, -3.8946e-03,  ..., -1.3835e-03,
         -4.2873e-05, -5.7045e-03],
        ...,
        [ 5.1968e-03, -1.8678e-03, -6.7434e-03,  ..., -1.7068e-03,
         -7.4910e-03,  1.2719e-03],
        [-6.8274e-04,  7.0441e-03, -3.3382e-04,  ..., -1.0300e-04,
         -3.1097e-03, -1.1004e-03],
        [ 7.6030e-03, -5.7270e-03,  2.2594e-03,  ..., -7.9484e-03,
         -5.7801e-03,  5.1960e-03]], requires_grad=True)
02: tensor([[-3.5725e-03, -2.2793e-03, -7.2209e-03,  6.2866e-03, -2.3313e-03,
         -8.4222e-03,  8.3713e-03, -6.2827e-04, -8.6839e-03, -1.4741e-02,
          8.0875e-04, -8.2737e-03, -2.4563e-03,  7.2471e-03, -2.5823e-03,
          4.2610e-03,  7.0515e-03, -1.1237e-03,  7.3271e-03, -3.4885e-03,
          2.7247e-03,  1.2257e-03, -7.2277e-03, -6.1745e-03,  1.9800e-03,
          3.1096e-03, -9.0302e-04,  5.8746e-03,  5.3402e-03, -5.3251e-03,
         -6.0768e-03, -2.5693e-03, -2.4769e-05,  5.7233e-03,  4.2430e-03,
         -1.9735e-03, -1.5062e-03,  1.8840e-03, -1.8724e-03,  1.6172e-04,
         -1.3053e-03, -8.0913e-03, -4.6094e-03,  2.7721e-03, -2.6132e-04,
          8.9300e-04,  2.4977e-03, -8.0139e-03,  3.2387e-03, -4.0056e-03,
          1.3422e-02,  8.5265e-03, -3.5319e-04,  3.2174e-03,  4.2439e-03,
         -1.2949e-02,  2.3827e-03, -4.2892e-03, -8.6890e-04,  5.9609e-03,
         -3.9257e-03, -5.0439e-03, -1.6120e-03, -2.2626e-03, -6.8422e-03,
          4.1526e-03,  4.6561e-03, -2.9468e-03, -2.8644e-03, -7.4167e-04,
         -4.5669e-04, -5.5742e-04, -8.7494e-03, -3.1949e-03,  5.1756e-03,
          9.5605e-03, -1.3477e-03,  5.7425e-04,  1.8556e-03,  7.1433e-03,
          5.7094e-03,  9.4800e-03,  9.3868e-03, -7.2104e-03, -4.9268e-03,
         -2.5346e-03, -1.0698e-02,  2.4551e-04,  7.8968e-03,  4.6767e-03,
         -3.0839e-03,  5.9919e-04, -8.4925e-03, -2.9584e-03, -6.8883e-03,
          1.9193e-03,  3.0812e-03,  5.1634e-03, -9.4409e-05, -9.4708e-04,
          9.9196e-04, -2.2077e-04, -1.9830e-03, -4.4410e-03,  3.1848e-03,
          7.8353e-03,  9.4941e-03, -4.9641e-03, -1.9408e-04, -1.1706e-03,
         -7.9724e-05,  1.5153e-03,  7.2713e-04, -2.5204e-03, -3.6029e-04,
         -8.5318e-03,  4.2428e-04, -5.3404e-03, -3.5137e-03,  3.7801e-03,
          5.6491e-04, -2.3353e-04, -5.0585e-03, -5.9800e-03, -2.9951e-03,
          3.4538e-03,  4.9973e-03, -2.6792e-03],
        [ 3.6718e-03, -1.4921e-03,  3.3446e-03,  7.9558e-03,  3.2801e-03,
          3.2575e-03,  8.0329e-03, -1.9352e-04,  4.0512e-03, -4.5807e-03,
          1.3368e-03,  8.2090e-03,  1.4303e-03,  1.1206e-03,  4.8481e-03,
          4.9658e-03,  5.6705e-04,  5.9788e-04, -2.3457e-03, -4.7816e-04,
         -1.5131e-03,  3.5578e-03,  5.3215e-03, -1.2594e-04, -1.1724e-03,
          1.0761e-04,  7.2413e-04,  8.0466e-03,  7.0385e-03, -3.3818e-03,
         -4.2314e-04, -4.7725e-03, -6.7101e-03, -1.1901e-02, -2.3774e-03,
         -3.8454e-03, -7.6560e-03, -1.9339e-03,  5.4052e-03, -4.5297e-04,
          3.8266e-03, -3.5556e-03, -1.6409e-03, -4.0096e-03, -2.6354e-03,
         -2.1105e-03,  1.7736e-03, -5.4474e-03,  4.2291e-03, -1.0279e-02,
          6.9080e-04,  5.7913e-03, -4.9716e-03, -6.1041e-04, -8.2417e-03,
          3.4873e-03,  3.7359e-03,  7.2499e-03,  9.3921e-03,  2.6159e-03,
          7.2958e-03, -4.1414e-03,  4.8470e-03, -5.4205e-03, -8.8178e-03,
          5.0139e-04,  7.8179e-03, -2.9508e-03, -1.4714e-03,  3.5239e-03,
          3.6360e-03, -1.5010e-03, -2.7991e-04,  4.1581e-03,  1.4763e-04,
         -5.3040e-04,  2.3333e-04, -4.2886e-03, -2.8568e-03, -4.2897e-03,
         -2.1707e-03,  7.2398e-03, -6.2133e-03,  8.8447e-03,  3.8652e-03,
          5.0846e-04, -8.7321e-03,  9.7763e-04, -8.5871e-03, -8.8308e-03,
         -3.3482e-03,  1.3052e-03, -3.9627e-03, -3.1060e-03, -1.3452e-02,
         -1.6092e-03,  1.8509e-03, -9.2973e-03, -4.3382e-03,  2.1008e-03,
          2.4167e-03, -3.0146e-03, -7.2665e-03,  6.7929e-04, -2.3921e-05,
         -7.6627e-03,  1.0062e-03,  2.9445e-03,  1.1269e-02, -5.0481e-03,
          6.8173e-03,  2.4680e-03, -6.5391e-04,  3.3577e-03,  5.5211e-03,
         -6.3438e-03,  1.1214e-03, -1.6332e-03, -9.8094e-03,  3.4465e-03,
          6.2361e-03, -6.6743e-03,  5.3690e-03,  3.4054e-03, -1.4130e-03,
          2.8880e-03, -1.9863e-03,  4.2890e-03]], requires_grad=True)
03: tensor([[-6.5642e-03, -8.3174e-06, -5.9820e-03,  ...,  5.5924e-03,
          7.8638e-04, -6.4967e-03],
        [ 3.7747e-03, -2.6141e-03, -1.5147e-03,  ...,  7.2409e-03,
         -3.8685e-03,  5.2470e-03],
        [ 3.3529e-03,  8.0881e-03,  5.4898e-03,  ...,  1.9210e-03,
          7.5434e-03, -3.8880e-03],
        ...,
        [ 1.0354e-02,  3.3689e-03, -5.7180e-03,  ...,  1.5856e-03,
          3.5077e-03, -2.0124e-04],
        [ 1.1782e-03,  3.8786e-03, -1.0843e-03,  ...,  1.1204e-03,
          4.1267e-03,  5.2406e-03],
        [ 1.6817e-03, -2.9645e-03, -5.8655e-03,  ..., -7.3724e-03,
         -6.4015e-03,  3.0634e-03]], requires_grad=True)
04: tensor([0.6157, 0.6814, 0.7622,  ..., 0.7807, 0.8489, 0.7935],
       requires_grad=True)
05: tensor([[ 0.0045, -0.0021,  0.0001,  ..., -0.0005, -0.0016,  0.0089],
        [-0.0033,  0.0041, -0.0045,  ...,  0.0056, -0.0008, -0.0081],
        [-0.0076, -0.0034,  0.0056,  ...,  0.0017, -0.0072, -0.0032],
        ...,
        [-0.0050, -0.0048,  0.0068,  ...,  0.0036,  0.0003, -0.0128],
        [-0.0062,  0.0063,  0.0061,  ...,  0.0066,  0.0054, -0.0046],
        [-0.0035,  0.0004,  0.0065,  ...,  0.0041,  0.0048,  0.0012]],
       requires_grad=True)
06: tensor([[ 0.0070,  0.0104,  0.0007,  ...,  0.0004, -0.0007,  0.0003],
        [-0.0057, -0.0003,  0.0014,  ...,  0.0001,  0.0096,  0.0028],
        [ 0.0050, -0.0063, -0.0024,  ...,  0.0013, -0.0053, -0.0074],
        ...,
        [-0.0023, -0.0104, -0.0055,  ...,  0.0057, -0.0022,  0.0010],
        [-0.0007,  0.0025,  0.0057,  ...,  0.0029, -0.0016,  0.0026],
        [-0.0006, -0.0038,  0.0014,  ...,  0.0003,  0.0032,  0.0091]],
       requires_grad=True)
07: tensor([[ 0.0185,  0.0294,  0.0135,  ..., -0.0085, -0.0007, -0.0130],
        [-0.0134, -0.0156,  0.0120,  ...,  0.0010,  0.0224,  0.0051],
        [-0.0198,  0.0012,  0.0089,  ..., -0.0109, -0.0121, -0.0094],
        ...,
        [ 0.0242, -0.0293,  0.0070,  ..., -0.0368,  0.0126,  0.0021],
        [ 0.0254,  0.0137,  0.0149,  ...,  0.0178,  0.0098, -0.0039],
        [-0.0247,  0.0156, -0.0046,  ..., -0.0005,  0.0020,  0.0063]],
       requires_grad=True)
08: tensor([[-0.0278, -0.0243,  0.0060,  ..., -0.0066,  0.0037,  0.0273],
        [ 0.0142,  0.0038, -0.0163,  ..., -0.0187,  0.0399,  0.0267],
        [-0.0008,  0.0114,  0.0114,  ...,  0.0024, -0.0064,  0.0077],
        ...,
        [ 0.0077,  0.0190,  0.0029,  ..., -0.0092,  0.0177, -0.0220],
        [-0.0053,  0.0020, -0.0102,  ...,  0.0120, -0.0273,  0.0275],
        [ 0.0066,  0.0200,  0.0389,  ..., -0.0086, -0.0185,  0.0009]],
       requires_grad=True)
09: tensor([[-0.0234,  0.0126, -0.0089,  ..., -0.0126, -0.0034,  0.0312],
        [-0.0181, -0.0008, -0.0066,  ...,  0.0013,  0.0005,  0.0122],
        [-0.0065,  0.0317, -0.0113,  ...,  0.0234, -0.0161, -0.0307],
        ...,
        [ 0.0200, -0.0182, -0.0198,  ..., -0.0047, -0.0328,  0.0099],
        [ 0.0016, -0.0110, -0.0190,  ..., -0.0064, -0.0186,  0.0086],
        [ 0.0272, -0.0073,  0.0068,  ...,  0.0090,  0.0180,  0.0115]],
       requires_grad=True)
10: tensor([[-1.5675e-02,  1.5414e-02,  1.5744e-02,  ...,  1.7177e-02,
          4.1461e-03, -3.6316e-02],
        [-1.5039e-02,  2.1214e-02,  7.8740e-03,  ...,  1.2372e-02,
         -3.8404e-02, -2.6513e-02],
        [ 1.8449e-02, -6.1271e-03, -3.3749e-03,  ..., -1.2810e-02,
         -1.4969e-02,  4.4078e-03],
        ...,
        [ 2.1173e-03, -1.9986e-02, -2.0176e-04,  ...,  1.5414e-02,
         -3.0756e-02, -1.2584e-02],
        [-1.5822e-02,  8.6330e-04, -1.2375e-02,  ..., -1.1702e-02,
          1.5849e-02,  1.4847e-02],
        [-1.4528e-02, -4.3896e-03,  4.0426e-04,  ..., -1.3441e-02,
         -4.1858e-03,  9.7474e-05]], requires_grad=True)
11: tensor([[ 0.0072,  0.0404,  0.0319,  ..., -0.0020,  0.0072,  0.0158],
        [ 0.0140,  0.0039,  0.0323,  ..., -0.0199, -0.0112,  0.0027],
        [ 0.0174, -0.0039, -0.0113,  ...,  0.0054, -0.0154, -0.0127],
        ...,
        [-0.0106,  0.0638,  0.0360,  ..., -0.0071,  0.0071,  0.0048],
        [ 0.0219, -0.0180,  0.0144,  ..., -0.0224,  0.0253,  0.0014],
        [-0.0193, -0.0147,  0.0114,  ...,  0.0140,  0.0403, -0.0066]],
       requires_grad=True)
12: tensor([[ 0.0214,  0.0141,  0.0323,  ...,  0.0137,  0.0062, -0.0325],
        [ 0.0204, -0.0190,  0.0137,  ...,  0.0011,  0.0206,  0.0167],
        [-0.0236, -0.0047, -0.0134,  ..., -0.0051,  0.0166, -0.0259],
        ...,
        [-0.0171,  0.0067, -0.0380,  ...,  0.0186, -0.0064, -0.0221],
        [ 0.0102, -0.0495,  0.0425,  ..., -0.0293,  0.0122,  0.0091],
        [-0.0114,  0.0334, -0.0245,  ...,  0.0094, -0.0093, -0.0029]],
       requires_grad=True)
13: tensor([[-0.0002, -0.0078,  0.0145,  ..., -0.0030, -0.0163, -0.0355],
        [ 0.0206,  0.0013,  0.0010,  ..., -0.0068,  0.0105, -0.0128]],
       requires_grad=True)
len(): 14
```





```py
self.extra_tensors
()
```


```py
main_parameters_and_extras
(tensor([[-0.0237, -0...grad=True), tensor([[ 7.0347e-03...grad=True), tensor([[-3.5725e-03...grad=True), tensor([[-6.5642e-03...grad=True), tensor([0.6157, 0.68...grad=True), tensor([[ 0.0045, -0...grad=True), tensor([[ 0.0070,  0...grad=True), tensor([[ 0.0185,  0...grad=True), tensor([[-0.0278, -0...grad=True), tensor([[-0.0234,  0...grad=True), tensor([[-1.5675e-02...grad=True), tensor([[ 0.0072,  0...grad=True), tensor([[ 0.0214,  0...grad=True), tensor([[-0.0002, -0...grad=True), ...)
```


```
num_parameters_and_extras
32
```

```
kwargs
{'timeout': 600.0}
```


# LOC

```py
loaded_state = super().load_state_from_peers(**kwargs)
```


```
loaded_state
({'epoch': 3755, 'group_bits': '', 'optimizer_metadata': [...]}, [tensor([[-0.0284, -0... 0.0400]]), tensor([[ 3.1412e-03...202e-03]]), tensor([[-1.5952e-03...151e-03]]), tensor([[-2.9311e-03...679e-03]]), tensor([0.4664, 0.56..., 0.7462]), tensor([[ 1.9965e-03...105e-04]]), tensor([[ 3.1226e-03...623e-03]]), tensor([[ 0.0128,  0... 0.0044]]), tensor([[-0.0242, -0... 0.0008]]), ...])
```


see

[see DecentralizedAverager load_state_from_peers](.vscode/linenote/hivemind/averaging/averager.py#L667.md)







































































































































































































































































































































































































































































































































































































































































































































































































































































































































































